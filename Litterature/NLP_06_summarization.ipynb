{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/simon-mellergaard/GAI-with-LLMs/blob/main/Litterature/NLP_06_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"colab_type":"text","id":"view-in-github"}},{"cell_type":"markdown","source":"[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/simonmellergaard/nlp-06-summarization/edit)","metadata":{}},{"cell_type":"code","source":"# Uncomment and run this cell if you're on Colab or Kaggle\n!git clone https://github.com/nlp-with-transformers/notebooks.git\n%cd notebooks\nfrom install import *\ninstall_requirements(is_chapter6=True)","metadata":{"id":"U5sCYhVI-C3_","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:08:55.428790Z","iopub.execute_input":"2025-09-17T06:08:55.428938Z","iopub.status.idle":"2025-09-17T06:10:48.816288Z","shell.execute_reply.started":"2025-09-17T06:08:55.428923Z","shell.execute_reply":"2025-09-17T06:10:48.815394Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'notebooks'...\nremote: Enumerating objects: 530, done.\u001b[K\nremote: Counting objects: 100% (241/241), done.\u001b[K\nremote: Compressing objects: 100% (55/55), done.\u001b[K\nremote: Total 530 (delta 209), reused 186 (delta 186), pack-reused 289 (from 1)\u001b[K\nReceiving objects: 100% (530/530), 34.57 MiB | 31.22 MiB/s, done.\nResolving deltas: 100% (249/249), done.\n/kaggle/working/notebooks\n⏳ Installing base requirements ...\n✅ Base requirements installed!\n⏳ Installing Git LFS ...\n✅ Git LFS installed!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#hide\nfrom utils import *\nsetup_chapter()","metadata":{"id":"ciGv2TxN-C4A","outputId":"9db473ec-71a0-4d48-89ef-c044726228ea","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:10:48.818006Z","iopub.execute_input":"2025-09-17T06:10:48.818275Z","iopub.status.idle":"2025-09-17T06:10:53.535422Z","shell.execute_reply.started":"2025-09-17T06:10:48.818252Z","shell.execute_reply":"2025-09-17T06:10:53.534660Z"}},"outputs":[{"name":"stdout","text":"Using transformers v4.16.2\nUsing datasets v2.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import pipeline, set_seed","metadata":{"id":"pCo0yaKG-C4B","outputId":"e8a97665-67ef-40d0-fd05-8eeb80b1e80d","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:13:59.781915Z","iopub.execute_input":"2025-09-17T06:13:59.782176Z","iopub.status.idle":"2025-09-17T06:14:29.266350Z","shell.execute_reply.started":"2025-09-17T06:13:59.782154Z","shell.execute_reply":"2025-09-17T06:14:29.265531Z"}},"outputs":[{"name":"stderr","text":"2025-09-17 06:14:12.002930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758089652.226110      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758089652.293624      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Summarization","metadata":{"id":"H4fkiDEo-C4D"}},{"cell_type":"markdown","source":"## The CNN/DailyMail Dataset","metadata":{"id":"dHaqYYpp-C4F"}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"ccdv/cnn_dailymail\", version=\"3.0.0\", trust_remote_code=True)\nprint(f\"Features: {dataset['train'].column_names}\")","metadata":{"colab":{"referenced_widgets":["437ab47eb9f7412680333b25ff8276b3"]},"id":"uVNC9ciI-C4H","outputId":"ee23b864-c468-41a2-8b05-e45ff19d24a3","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:21:15.589793Z","iopub.execute_input":"2025-09-17T06:21:15.590881Z","iopub.status.idle":"2025-09-17T06:21:15.891895Z","shell.execute_reply.started":"2025-09-17T06:21:15.590841Z","shell.execute_reply":"2025-09-17T06:21:15.891028Z"}},"outputs":[{"name":"stdout","text":"Features: ['article', 'highlights', 'id']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"sample = dataset[\"train\"][1]\nprint(f\"\"\"\nArticle (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n\"\"\")\nprint(sample[\"article\"][:500])\nprint(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\nprint(sample[\"highlights\"])","metadata":{"id":"yyOuzRmS-C4J","outputId":"5b0c8168-7c7b-4dae-c6c1-98a3872bd16d","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:19:01.495927Z","iopub.execute_input":"2025-09-17T06:19:01.496874Z","iopub.status.idle":"2025-09-17T06:19:01.502305Z","shell.execute_reply.started":"2025-09-17T06:19:01.496844Z","shell.execute_reply":"2025-09-17T06:19:01.501323Z"}},"outputs":[{"name":"stdout","text":"\nArticle (excerpt of 500 characters, total length: 3192):\n\n(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has n\n\nSummary (length: 180):\nUsain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Text Summarization Pipelines","metadata":{"id":"TfHF7LMU-C4L"}},{"cell_type":"code","source":"sample_text = dataset[\"train\"][1][\"article\"][:2000]\n# We'll collect the generated summaries of each model in a dictionary\nsummaries = {}","metadata":{"id":"79L8py9k-C4L","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:19:18.682216Z","iopub.execute_input":"2025-09-17T06:19:18.682547Z","iopub.status.idle":"2025-09-17T06:19:18.686958Z","shell.execute_reply.started":"2025-09-17T06:19:18.682525Z","shell.execute_reply":"2025-09-17T06:19:18.686116Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download(\"punkt\")","metadata":{"id":"IbynKL-P-C4N","outputId":"b209fd5b-28f0-4e0d-b9d7-4b65c45fe4d9","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:19:36.209536Z","iopub.execute_input":"2025-09-17T06:19:36.210377Z","iopub.status.idle":"2025-09-17T06:19:36.833153Z","shell.execute_reply.started":"2025-09-17T06:19:36.210348Z","shell.execute_reply":"2025-09-17T06:19:36.832526Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"string = \"The U.S. are a country. The U.N. is an organization.\"\nsent_tokenize(string)","metadata":{"id":"VuDcEB0w-C4P","outputId":"e5d67b08-ecf8-40af-e1f1-2fe6eb94db06","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:19:44.328768Z","iopub.execute_input":"2025-09-17T06:19:44.329068Z","iopub.status.idle":"2025-09-17T06:19:44.361859Z","shell.execute_reply.started":"2025-09-17T06:19:44.329045Z","shell.execute_reply":"2025-09-17T06:19:44.361147Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['The U.S. are a country.', 'The U.N. is an organization.']"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Summarization Baseline\n","metadata":{"id":"r75aYFVB-C4Q"}},{"cell_type":"code","source":"def three_sentence_summary(text):\n    return \"\\n\".join(sent_tokenize(text)[:3])","metadata":{"id":"RZzzdy-B-C4R","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:20:10.090487Z","iopub.execute_input":"2025-09-17T06:20:10.090767Z","iopub.status.idle":"2025-09-17T06:20:10.094899Z","shell.execute_reply.started":"2025-09-17T06:20:10.090748Z","shell.execute_reply":"2025-09-17T06:20:10.093965Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"summaries[\"baseline\"] = three_sentence_summary(sample_text)","metadata":{"id":"MzNcZr6W-C4S","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:20:11.634786Z","iopub.execute_input":"2025-09-17T06:20:11.635544Z","iopub.status.idle":"2025-09-17T06:20:11.639163Z","shell.execute_reply.started":"2025-09-17T06:20:11.635511Z","shell.execute_reply":"2025-09-17T06:20:11.638546Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### GPT-2","metadata":{"id":"O4tSoZ-V-C4S"}},{"cell_type":"code","source":"#hide_output\nfrom transformers import pipeline, set_seed\n\nset_seed(42)\npipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\ngpt2_query = sample_text + \"\\nTL;DR:\\n\"\npipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\nsummaries[\"gpt2\"] = \"\\n\".join(\n    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))","metadata":{"id":"MJZdhgZq-C4S","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:22:27.889768Z","iopub.execute_input":"2025-09-17T06:22:27.890399Z","iopub.status.idle":"2025-09-17T06:23:26.114800Z","shell.execute_reply.started":"2025-09-17T06:22:27.890374Z","shell.execute_reply":"2025-09-17T06:23:26.114145Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c750a61b15d84188a3af9ae5c948c77f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f703082c1974628bad6ac21687fd93d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ffe95d9285246a8a6d2350c14f76a05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb13a91e13d14dcc87d813046edffb5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3f5eed882994aff9fea88f7fb7f013f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"042168d5d44b4e5e89414f6593bd8658"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7834793c64924fb79d047952c3f6aa4d"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### T5","metadata":{"id":"uHG9Gw4Z-C4T"}},{"cell_type":"markdown","source":"<img alt=\"T5\" width=\"700\" caption=\"Diagram of T5's text-to-text framework (courtesy of Colin Raffel); besides translation and summarization, the CoLA (linguistic acceptability) and STSB (semantic similarity) tasks are shown\" src=\"https://github.com/nlp-with-transformers/notebooks/blob/main/images/chapter08_t5.png?raw=1\" id=\"T5\"/>","metadata":{"id":"noqZp7Mb-C4T"}},{"cell_type":"code","source":"#hide_output\npipe = pipeline(\"summarization\", model=\"t5-large\")\npipe_out = pipe(sample_text)\nsummaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))","metadata":{"id":"FMp0vHgi-C4T","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:24:35.497959Z","iopub.execute_input":"2025-09-17T06:24:35.498758Z","iopub.status.idle":"2025-09-17T06:24:55.182042Z","shell.execute_reply.started":"2025-09-17T06:24:35.498732Z","shell.execute_reply":"2025-09-17T06:24:55.181450Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f839bbea3089443d8c535c148b766bc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27d4e29b846746279a026ade9e83f31c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1494ffc33e49259f03be55b6b00251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d0693c9e84c49dda9b413d11e4a3216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"899d27488d744dfd8668d2c8c6451d9b"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### BART","metadata":{"id":"wvRS0OHU-C4T"}},{"cell_type":"code","source":"#hide_output\npipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\npipe_out = pipe(sample_text)\nsummaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))","metadata":{"id":"D-sFpsML-C4T","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:25:18.465867Z","iopub.execute_input":"2025-09-17T06:25:18.466151Z","iopub.status.idle":"2025-09-17T06:25:27.761145Z","shell.execute_reply.started":"2025-09-17T06:25:18.466132Z","shell.execute_reply":"2025-09-17T06:25:27.760320Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95865ab6dc59411893f7b42341d2bf38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c022fa128224d448c027296e6cd4f98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a591b440b344678a67393d08f90e6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29bbc013355c4adf812723dfb377a5d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3aefd320eb54cafbcf7a98106cd5151"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2471739f9ef4b1ca6b5c6a33cfb0878"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### PEGASUS","metadata":{"id":"k6qWTK9s-C4U"}},{"cell_type":"markdown","source":"<img alt=\"pegasus\" width=\"700\" caption=\"Diagram of PEGASUS architecture (courtesy of Jingqing Zhang et al.)\" src=\"https://github.com/nlp-with-transformers/notebooks/blob/main/images/chapter08_pegasus.png?raw=1\" id=\"pegasus\"/>","metadata":{"id":"641ykWFb-C4U"}},{"cell_type":"code","source":"#hide_output\npipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\npipe_out = pipe(sample_text)\nsummaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")","metadata":{"id":"I7ruabL6-C4U","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:26:17.134646Z","iopub.execute_input":"2025-09-17T06:26:17.135369Z","iopub.status.idle":"2025-09-17T06:26:51.314004Z","shell.execute_reply.started":"2025-09-17T06:26:17.135342Z","shell.execute_reply":"2025-09-17T06:26:51.313356Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99c115f660d34dcdb813be0ca94a8c53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b902556b34a5463481d414b26dcd2660"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4a221a521084fee81eed9ddbf2ab45c"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f804507508d4694b99dcd17d49db093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"031d9da49dcc4a39bee10d330356ddee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff01468762c49bfb9e503d98df53c45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19c38518486f4682a6b26dad57bb64d8"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Comparing Different Summaries","metadata":{"id":"rbVEUFzx-C4U"}},{"cell_type":"code","source":"print(\"GROUND TRUTH\")\nprint(dataset[\"train\"][1][\"highlights\"])\nprint(\"\")\n\nfor model_name in summaries:\n    print(model_name.upper())\n    print(summaries[model_name])\n    print(\"\")","metadata":{"id":"tK55o3Kg-C4U","outputId":"8fd4575b-e913-4a95-a30e-ca2c2774ee3b","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:26:57.143553Z","iopub.execute_input":"2025-09-17T06:26:57.144145Z","iopub.status.idle":"2025-09-17T06:26:57.165826Z","shell.execute_reply.started":"2025-09-17T06:26:57.144121Z","shell.execute_reply":"2025-09-17T06:26:57.165065Z"}},"outputs":[{"name":"stdout","text":"GROUND TRUTH\nUsain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .\n\nBASELINE\n(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n\nGPT2\n- Usain Bolt won the 100m and 200m gold medals, making him the third fastest man in the world\n- A third gold at this year's world championships means he is on course to surpass Michael Johnson's record of 10 Olympic medals\n- Bolt is now on course to win 10 gold medals.\nMichael Johnson now has 5 Olympic medals and has already reached double figures in Olympic medals in each of his two Olympic years\n- Bolt had already equalled the record for most gold medals by a single athlete at a single Olympics - Johnson has won 10 gold medals at the 2004 Athens Games and 11 at London 2012\n- Bolt's 10 Olympic medals are more than the number of medals won by every other Olympic athlete combined\n- Usain Bolt is the only man in the history of athletics to win multiple Olympic gold medals at two different Olympics\n- Bolt is also the only man in the history of athletics to win multiple world championship gold medals at two different Olympics\n\nT5\nusain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\nthe 26-year-old anchored Jamaica to victory in the event in the Russian capital .\nhe has now collected eight gold medals at the championships, equaling the record .\n\nBART\nUsain Bolt wins his third gold of the world championships in Moscow.\nBolt anchors Jamaica to victory in the men's 4x100m relay.\nThe 26-year-old has now won eight gold medals at world championships.\nJamaica's women also win gold in the relay, beating France in the process.\n\nPEGASUS\nUsain Bolt wins third gold of world championships.\nAnchors Jamaica to victory in men's 4x100m relay.\nEighth gold at the championships for Bolt.\nJamaica also win women's 4x100m relay .\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Measuring the Quality of Generated Text","metadata":{"id":"7QKWMtHc-C4U"}},{"cell_type":"markdown","source":"### BLEU","metadata":{"id":"3Wnstti2-C4V"}},{"cell_type":"code","source":"!pip install evaluate\n!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:50:07.805688Z","iopub.execute_input":"2025-09-17T06:50:07.806428Z","iopub.status.idle":"2025-09-17T06:50:11.685147Z","shell.execute_reply.started":"2025-09-17T06:50:07.806396Z","shell.execute_reply":"2025-09-17T06:50:11.684072Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.2.0 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# hide_output\n# from datasets import load_metric\n\n# bleu_metric = load_metric(\"sacrebleu\")\nimport evaluate\nbleu_metric = evaluate.load(\"sacrebleu\")","metadata":{"id":"y543Vwam-C4V","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:50:14.117077Z","iopub.execute_input":"2025-09-17T06:50:14.117947Z","iopub.status.idle":"2025-09-17T06:50:14.535868Z","shell.execute_reply.started":"2025-09-17T06:50:14.117912Z","shell.execute_reply":"2025-09-17T06:50:14.535251Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nbleu_metric.add(\n    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\nresults[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])","metadata":{"id":"bL7k1ROg-C4X","outputId":"8964ad2e-6a79-42fd-b7ed-25c3c621c422","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:50:21.699835Z","iopub.execute_input":"2025-09-17T06:50:21.700994Z","iopub.status.idle":"2025-09-17T06:50:21.762434Z","shell.execute_reply.started":"2025-09-17T06:50:21.700966Z","shell.execute_reply":"2025-09-17T06:50:21.761766Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                             Value\nscore                          0.0\ncounts                [2, 0, 0, 0]\ntotals                [6, 5, 4, 3]\nprecisions  [33.33, 0.0, 0.0, 0.0]\nbp                             1.0\nsys_len                          6\nref_len                          6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>score</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>counts</th>\n      <td>[2, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>totals</th>\n      <td>[6, 5, 4, 3]</td>\n    </tr>\n    <tr>\n      <th>precisions</th>\n      <td>[33.33, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>bp</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>sys_len</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>ref_len</th>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"bleu_metric.add(\n    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\nresults[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])","metadata":{"id":"LcPkjVP7-C4Y","outputId":"8945d9dd-f95e-4b85-c6fb-cec3ea9d4182","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T06:53:46.912932Z","iopub.execute_input":"2025-09-17T06:53:46.913657Z","iopub.status.idle":"2025-09-17T06:53:46.931825Z","shell.execute_reply.started":"2025-09-17T06:53:46.913629Z","shell.execute_reply":"2025-09-17T06:53:46.930955Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                 Value\nscore                        57.893007\ncounts                    [5, 3, 2, 1]\ntotals                    [5, 4, 3, 2]\nprecisions  [100.0, 75.0, 66.67, 50.0]\nbp                            0.818731\nsys_len                              5\nref_len                              6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>score</th>\n      <td>57.893007</td>\n    </tr>\n    <tr>\n      <th>counts</th>\n      <td>[5, 3, 2, 1]</td>\n    </tr>\n    <tr>\n      <th>totals</th>\n      <td>[5, 4, 3, 2]</td>\n    </tr>\n    <tr>\n      <th>precisions</th>\n      <td>[100.0, 75.0, 66.67, 50.0]</td>\n    </tr>\n    <tr>\n      <th>bp</th>\n      <td>0.818731</td>\n    </tr>\n    <tr>\n      <th>sys_len</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>ref_len</th>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"### ROUGE","metadata":{"id":"52f4IYxq-C4a"}},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:04:35.917638Z","iopub.execute_input":"2025-09-17T07:04:35.918212Z","iopub.status.idle":"2025-09-17T07:04:41.541392Z","shell.execute_reply.started":"2025-09-17T07:04:35.918188Z","shell.execute_reply":"2025-09-17T07:04:41.540530Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=c71f1bc536f336adad555973a23c8476e911d5d6f0c7230bcaabc1f2cc7e7e51\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"rouge_metric = evaluate.load(\"rouge\")","metadata":{"id":"GUul241G-C4b","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:04:46.495839Z","iopub.execute_input":"2025-09-17T07:04:46.496652Z","iopub.status.idle":"2025-09-17T07:04:46.828894Z","shell.execute_reply.started":"2025-09-17T07:04:46.496618Z","shell.execute_reply":"2025-09-17T07:04:46.828308Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"reference = dataset[\"train\"][1][\"highlights\"]\nrecords = []\nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n\nfor model_name in summaries:\n    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n    score = rouge_metric.compute()\n    rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n    records.append(rouge_dict)\npd.DataFrame.from_records(records, index=summaries.keys())","metadata":{"id":"swks9VbO-C4b","outputId":"58befdfe-7e00-4e70-b1d7-5f2998aa49f9","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:05:26.032975Z","iopub.execute_input":"2025-09-17T07:05:26.033587Z","iopub.status.idle":"2025-09-17T07:05:26.797117Z","shell.execute_reply.started":"2025-09-17T07:05:26.033560Z","shell.execute_reply":"2025-09-17T07:05:26.796344Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"            rouge1    rouge2    rougeL  rougeLsum\nbaseline  0.303571  0.090909  0.214286   0.232143\ngpt2      0.170000  0.050505  0.110000   0.150000\nt5        0.486486  0.222222  0.378378   0.486486\nbart      0.582278  0.207792  0.455696   0.506329\npegasus   0.866667  0.655172  0.800000   0.833333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline</th>\n      <td>0.303571</td>\n      <td>0.090909</td>\n      <td>0.214286</td>\n      <td>0.232143</td>\n    </tr>\n    <tr>\n      <th>gpt2</th>\n      <td>0.170000</td>\n      <td>0.050505</td>\n      <td>0.110000</td>\n      <td>0.150000</td>\n    </tr>\n    <tr>\n      <th>t5</th>\n      <td>0.486486</td>\n      <td>0.222222</td>\n      <td>0.378378</td>\n      <td>0.486486</td>\n    </tr>\n    <tr>\n      <th>bart</th>\n      <td>0.582278</td>\n      <td>0.207792</td>\n      <td>0.455696</td>\n      <td>0.506329</td>\n    </tr>\n    <tr>\n      <th>pegasus</th>\n      <td>0.866667</td>\n      <td>0.655172</td>\n      <td>0.800000</td>\n      <td>0.833333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"## Evaluating PEGASUS on the CNN/DailyMail Dataset","metadata":{"id":"5Bn1K8fC-C4c"}},{"cell_type":"code","source":"def evaluate_summaries_baseline(dataset, metric,\n                                column_text=\"article\",\n                                column_summary=\"highlights\"):\n    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n    metric.add_batch(predictions=summaries,\n                     references=dataset[column_summary])\n    score = metric.compute()\n    return score","metadata":{"id":"qtaBseXU-C4d","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:08:32.200030Z","iopub.execute_input":"2025-09-17T07:08:32.200974Z","iopub.status.idle":"2025-09-17T07:08:32.207082Z","shell.execute_reply.started":"2025-09-17T07:08:32.200937Z","shell.execute_reply":"2025-09-17T07:08:32.206152Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n\nscore = evaluate_summaries_baseline(test_sampled, rouge_metric)\nrouge_dict = dict((rn, score[rn]) for rn in rouge_names)\npd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T","metadata":{"id":"Z-3D2nGV-C4d","outputId":"e881ad29-35d9-43ad-ab70-a7d7779e5476","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:09:36.546573Z","iopub.execute_input":"2025-09-17T07:09:36.546870Z","iopub.status.idle":"2025-09-17T07:09:40.067732Z","shell.execute_reply.started":"2025-09-17T07:09:36.546846Z","shell.execute_reply":"2025-09-17T07:09:40.066887Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"            rouge1    rouge2   rougeL  rougeLsum\nbaseline  0.388019  0.170517  0.24714   0.354912","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline</th>\n      <td>0.388019</td>\n      <td>0.170517</td>\n      <td>0.24714</td>\n      <td>0.354912</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef chunks(list_of_elements, batch_size):\n    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\ndef evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n                               batch_size=8, device=device,\n                               column_text=\"article\",\n                               column_summary=\"highlights\"):\n    article_batches = list(chunks(dataset[column_text], batch_size))\n    target_batches = list(chunks(dataset[column_summary], batch_size))\n\n    for article_batch, target_batch in tqdm(\n        zip(article_batches, target_batches), total=len(article_batches)):\n\n        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n                        padding=\"max_length\", return_tensors=\"pt\")\n\n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                         attention_mask=inputs[\"attention_mask\"].to(device),\n                         length_penalty=0.8, num_beams=8, max_length=128)\n\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n                                clean_up_tokenization_spaces=True)\n               for s in summaries]\n        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n\n    score = metric.compute()\n    return score","metadata":{"id":"cwMxxuJc-C4d","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:14:20.673072Z","iopub.execute_input":"2025-09-17T07:14:20.673439Z","iopub.status.idle":"2025-09-17T07:14:20.681407Z","shell.execute_reply.started":"2025-09-17T07:14:20.673413Z","shell.execute_reply":"2025-09-17T07:14:20.680598Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# hide_output\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_ckpt = \"google/pegasus-cnn_dailymail\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\nscore = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n                                   model, tokenizer, batch_size=2) # REDUCED BATCH SIZE\n","metadata":{"id":"1gXjk0r2-C4i","outputId":"a3ec4b9d-3335-488b-8628-05948cfb4a08","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:15:13.161990Z","iopub.execute_input":"2025-09-17T07:15:13.162296Z","iopub.status.idle":"2025-09-17T08:02:04.993582Z","shell.execute_reply.started":"2025-09-17T07:15:13.162254Z","shell.execute_reply":"2025-09-17T08:02:04.992410Z"}},"outputs":[{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n100%|██████████| 500/500 [46:40<00:00,  5.60s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/693075319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n\u001b[1;32m      8\u001b[0m                                    model, tokenizer, batch_size=2) # REDUCED BATCH SIZE\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrouge_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmeasure\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrouge_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrouge_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pegasus\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/693075319.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n\u001b[1;32m      8\u001b[0m                                    model, tokenizer, batch_size=2) # REDUCED BATCH SIZE\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrouge_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmeasure\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrouge_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrouge_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pegasus\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"],"ename":"AttributeError","evalue":"'numpy.float64' object has no attribute 'mid'","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:02:37.378084Z","iopub.execute_input":"2025-09-17T08:02:37.378791Z","iopub.status.idle":"2025-09-17T08:02:37.390426Z","shell.execute_reply.started":"2025-09-17T08:02:37.378763Z","shell.execute_reply":"2025-09-17T08:02:37.389738Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"           rouge1    rouge2   rougeL  rougeLsum\npegasus  0.427037  0.207522  0.30509   0.369171","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pegasus</th>\n      <td>0.427037</td>\n      <td>0.207522</td>\n      <td>0.30509</td>\n      <td>0.369171</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"## Training a Summarization Model","metadata":{"id":"I0O0YzY9-C4j"}},{"cell_type":"code","source":"# hide_output\ndataset_samsum = load_dataset(\"knkarthick/samsum\")\ndataset_samsum[\"train\"] = dataset_samsum[\"train\"].select(\n    [i for i in range(len(dataset_samsum[\"train\"])) if i != 6054]\n)\nsplit_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n\nprint(f\"Split lengths: {split_lengths}\")\nprint(f\"Features: {dataset_samsum['train'].column_names}\")\nprint(\"\\nDialogue:\")\nprint(dataset_samsum[\"test\"][0][\"dialogue\"])\nprint(\"\\nSummary:\")\nprint(dataset_samsum[\"test\"][0][\"summary\"])","metadata":{"id":"YOV89xC2-C4j","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:04:29.867561Z","iopub.execute_input":"2025-09-17T08:04:29.867885Z","iopub.status.idle":"2025-09-17T08:04:30.272206Z","shell.execute_reply.started":"2025-09-17T08:04:29.867863Z","shell.execute_reply":"2025-09-17T08:04:30.271590Z"}},"outputs":[{"name":"stdout","text":"Split lengths: [14732, 818, 819]\nFeatures: ['id', 'dialogue', 'summary']\n\nDialogue:\nHannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nHannah: <file_gif>\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nHannah: <file_gif>\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him 🙂\nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n\nSummary:\nHannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"### Evaluating PEGASUS on SAMSum","metadata":{"id":"dJ6Dzidu-C4k"}},{"cell_type":"code","source":"pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\nprint(\"Summary:\")\nprint(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))","metadata":{"id":"YyN8lWZg-C4k","outputId":"c7ec9ce3-747f-4e60-9a54-a427e8cb8fc9","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:05:10.206712Z","iopub.execute_input":"2025-09-17T08:05:10.207213Z","iopub.status.idle":"2025-09-17T08:05:11.091484Z","shell.execute_reply.started":"2025-09-17T08:05:10.207187Z","shell.execute_reply":"2025-09-17T08:05:11.090602Z"}},"outputs":[{"name":"stderr","text":"Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n","output_type":"stream"},{"name":"stdout","text":"Summary:\nAmanda: Ask Larry Amanda: He called her last time we were at the park together.\nHannah: I'd rather you texted him.\nAmanda: Just text him .\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n                                   tokenizer, column_text=\"dialogue\",\n                                   column_summary=\"summary\", batch_size=8)\n\nrouge_dict = dict((rn, score[rn]) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"id":"x-8mSUdb-C4k","outputId":"862283f8-5ea3-4405-fc8b-40d05d84b480","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:06:28.554330Z","iopub.execute_input":"2025-09-17T08:06:28.555068Z","iopub.status.idle":"2025-09-17T08:06:42.010424Z","shell.execute_reply.started":"2025-09-17T08:06:28.555042Z","shell.execute_reply":"2025-09-17T08:06:42.009326Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/103 [00:13<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2214033265.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# hide_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                    \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dialogue\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    column_summary=\"summary\", batch_size=8)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2125888244.py\u001b[0m in \u001b[0;36mevaluate_summaries_pegasus\u001b[0;34m(dataset, metric, model, tokenizer, batch_size, device, column_text, column_summary)\u001b[0m\n\u001b[1;32m     22\u001b[0m                         padding=\"max_length\", return_tensors=\"pt\")\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n\u001b[0m\u001b[1;32m     25\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                          length_penalty=0.8, num_beams=8, max_length=128)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2614\u001b[0m             )\n\u001b[1;32m   2615\u001b[0m             \u001b[0;31m# 12. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2617\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   4134\u001b[0m             \u001b[0;31m# pluck the cache from the beam indices that will be used in the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4136\u001b[0;31m                 model_kwargs[\"past_key_values\"] = self._temporary_reorder_cache(\n\u001b[0m\u001b[1;32m   4137\u001b[0m                     \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4138\u001b[0m                     \u001b[0mbeam_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_beam_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_beam_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdecoder_prompt_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_temporary_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   3660\u001b[0m         \u001b[0;31m# Exception 1: code path for models using the legacy cache format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3662\u001b[0;31m             \u001b[0mpast_key_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3663\u001b[0m         \u001b[0;31m# Exception 2: models with different cache formats. These are limited to `DynamicCache` until their\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3664\u001b[0m         \u001b[0;31m# cache format is standardized, to avoid adding complexity to the codebase.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36m_reorder_cache\u001b[0;34m(past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# cached cross_attention states don't have to be reordered -> they are always the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             reordered_past += (\n\u001b[0;32m-> 1497\u001b[0;31m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpast_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1498\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;31m# cached cross_attention states don't have to be reordered -> they are always the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             reordered_past += (\n\u001b[0;32m-> 1497\u001b[0;31m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpast_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1498\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             )\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 14.12 MiB is free. Process 3600 has 14.72 GiB memory in use. Of the allocated memory 14.39 GiB is allocated by PyTorch, and 216.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 14.12 MiB is free. Process 3600 has 14.72 GiB memory in use. Of the allocated memory 14.39 GiB is allocated by PyTorch, and 216.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":53},{"cell_type":"code","source":"# hide_input\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"id":"8zqXgffR-C4k","outputId":"d2847a94-05ba-476f-a0cc-547692a905a6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fine-Tuning PEGASUS","metadata":{"id":"pT7NKb3z-C4l"}},{"cell_type":"code","source":"d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"][:6055]]\ns_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"][:6055]]\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\naxes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\naxes[0].set_title(\"Dialogue Token Length\")\naxes[0].set_xlabel(\"Length\")\naxes[0].set_ylabel(\"Count\")\naxes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\naxes[1].set_title(\"Summary Token Length\")\naxes[1].set_xlabel(\"Length\")\nplt.tight_layout()\nplt.show()","metadata":{"id":"baIkJh4v-C4l","outputId":"648e38bc-e958-4ae4-c0e1-6e31743988df","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:38:49.730772Z","iopub.execute_input":"2025-09-17T08:38:49.731368Z","iopub.status.idle":"2025-09-17T08:38:54.166918Z","shell.execute_reply.started":"2025-09-17T08:38:49.731341Z","shell.execute_reply":"2025-09-17T08:38:54.166248Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x350 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":103},{"cell_type":"code","source":"#hide_output\ndef convert_examples_to_features(example_batch):\n    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n                                truncation=True)\n\n    with tokenizer.as_target_tokenizer():\n        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n                                     truncation=True)\n\n    return {\"input_ids\": input_encodings[\"input_ids\"],\n            \"attention_mask\": input_encodings[\"attention_mask\"],\n            \"labels\": target_encodings[\"input_ids\"]}\n\ndataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n                                       batched=True)\ncolumns = [\"input_ids\", \"labels\", \"attention_mask\"]\ndataset_samsum_pt.set_format(type=\"torch\", columns=columns)","metadata":{"id":"-aTydYAd-C4l","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:39:35.997643Z","iopub.execute_input":"2025-09-17T08:39:35.998429Z","iopub.status.idle":"2025-09-17T08:39:36.052423Z","shell.execute_reply.started":"2025-09-17T08:39:35.998400Z","shell.execute_reply":"2025-09-17T08:39:36.051574Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"#hide_input\n\n#id teacher-forcing\n#alt Decoder input and label alignemt for text generation.\n#caption Decoder input and label alignemt for text generation.\ntext = ['PAD','Transformers', 'are', 'awesome', 'for', 'text', 'summarization']\nrows = []\nfor i in range(len(text)-1):\n    rows.append({'step': i+1, 'decoder_input': text[:i+1], 'label': text[i+1]})\npd.DataFrame(rows).set_index('step')","metadata":{"id":"4li83sJw-C4m","outputId":"87cad435-ac39-454b-f8c2-db89781629c1","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:39:37.812744Z","iopub.execute_input":"2025-09-17T08:39:37.813362Z","iopub.status.idle":"2025-09-17T08:39:37.828451Z","shell.execute_reply.started":"2025-09-17T08:39:37.813337Z","shell.execute_reply":"2025-09-17T08:39:37.827700Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"                                     decoder_input          label\nstep                                                             \n1                                            [PAD]   Transformers\n2                              [PAD, Transformers]            are\n3                         [PAD, Transformers, are]        awesome\n4                [PAD, Transformers, are, awesome]            for\n5           [PAD, Transformers, are, awesome, for]           text\n6     [PAD, Transformers, are, awesome, for, text]  summarization","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>decoder_input</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>step</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>[PAD]</td>\n      <td>Transformers</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[PAD, Transformers]</td>\n      <td>are</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[PAD, Transformers, are]</td>\n      <td>awesome</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[PAD, Transformers, are, awesome]</td>\n      <td>for</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[PAD, Transformers, are, awesome, for]</td>\n      <td>text</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[PAD, Transformers, are, awesome, for, text]</td>\n      <td>summarization</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\nseq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"id":"kL4CTulF-C4n","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:40:17.432022Z","iopub.execute_input":"2025-09-17T08:40:17.432870Z","iopub.status.idle":"2025-09-17T08:40:17.436588Z","shell.execute_reply.started":"2025-09-17T08:40:17.432841Z","shell.execute_reply":"2025-09-17T08:40:17.435767Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n    weight_decay=0.01, logging_steps=10, push_to_hub=True,\n    eval_strategy='steps', eval_steps=500, save_steps=1e6,\n    gradient_accumulation_steps=16)","metadata":{"id":"rDTnokgj-C4o","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:41:06.800601Z","iopub.execute_input":"2025-09-17T08:41:06.801344Z","iopub.status.idle":"2025-09-17T08:41:06.847042Z","shell.execute_reply.started":"2025-09-17T08:41:06.801318Z","shell.execute_reply":"2025-09-17T08:41:06.846212Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"# Logging in to HF from Kaggle\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nfrom huggingface_hub import login as login_hf\nlogin_hf(user_secrets.get_secret(\"HF\"))","metadata":{"colab":{"referenced_widgets":["04f65c507a094c53a28628b65aad0b0b"]},"id":"7JaIPzZh-C4p","outputId":"c535a325-fad3-49ce-e039-1d2b2bcdeee0","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:43:04.995091Z","iopub.execute_input":"2025-09-17T08:43:04.995890Z","iopub.status.idle":"2025-09-17T08:43:05.201379Z","shell.execute_reply.started":"2025-09-17T08:43:04.995863Z","shell.execute_reply":"2025-09-17T08:43:05.200580Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"# hide_output\ntrainer = Trainer(model=model, args=training_args,\n                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n                  train_dataset=dataset_samsum_pt[\"train\"],\n                  eval_dataset=dataset_samsum_pt[\"validation\"])","metadata":{"id":"d6vftRrT-C4p","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:43:10.641641Z","iopub.execute_input":"2025-09-17T08:43:10.641914Z","iopub.status.idle":"2025-09-17T08:43:14.094865Z","shell.execute_reply.started":"2025-09-17T08:43:10.641893Z","shell.execute_reply":"2025-09-17T08:43:14.094216Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/4025212638.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(model=model, args=training_args,\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"#import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:47:19.480899Z","iopub.execute_input":"2025-09-17T08:47:19.481727Z","iopub.status.idle":"2025-09-17T08:47:19.594094Z","shell.execute_reply.started":"2025-09-17T08:47:19.481702Z","shell.execute_reply":"2025-09-17T08:47:19.593534Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"# hide_output\ntrainer.train()\nscore = evaluate_summaries_pegasus(\n    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n    batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n\nrouge_dict = dict((rn, score[rn]) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[f\"pegasus\"])","metadata":{"id":"gStqGnB4-C4p","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:47:32.467361Z","iopub.execute_input":"2025-09-17T08:47:32.467913Z","iopub.status.idle":"2025-09-17T08:47:33.405957Z","shell.execute_reply.started":"2025-09-17T08:47:32.467891Z","shell.execute_reply":"2025-09-17T08:47:33.404899Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1965962298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# hide_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m score = evaluate_summaries_pegasus(\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset_samsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouge_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2229\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2231\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   2232\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m                     )\n\u001b[1;32m   2554\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3789\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3793\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2553\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 116.12 MiB is free. Process 3600 has 14.62 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 291.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 116.12 MiB is free. Process 3600 has 14.62 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 291.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":117},{"cell_type":"code","source":"# hide_input\npd.DataFrame(rouge_dict, index=[f\"pegasus\"])","metadata":{"id":"hscueELK-C4q","outputId":"3802ce60-239c-4f0a-c342-9e16940d3e79"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_output\ntrainer.push_to_hub(\"Training complete!\")","metadata":{"id":"PgDbZVQ4-C4r","outputId":"7e671eea-c11e-4fa5-efb6-bbb36a3fa38b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Generating Dialogue Summaries","metadata":{"id":"2RozmEBY-C4r"}},{"cell_type":"code","source":"# hide\nimport transformers\ntransformers.logging.set_verbosity_error()","metadata":{"id":"crf5PP6c-C4r"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\nsample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\nreference = dataset_samsum[\"test\"][0][\"summary\"]\npipe = pipeline(\"summarization\", model=\"transformersbook/pegasus-samsum\")\n\nprint(\"Dialogue:\")\nprint(sample_text)\nprint(\"\\nReference Summary:\")\nprint(reference)\nprint(\"\\nModel Summary:\")\nprint(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])","metadata":{"id":"2zYIYE6G-C4s","outputId":"ed1fbf72-ac81-44e6-b3e8-21da45df7d32"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"custom_dialogue = \"\"\"\\\nThom: Hi guys, have you heard of transformers?\nLewis: Yes, I used them recently!\nLeandro: Indeed, there is a great library by Hugging Face.\nThom: I know, I helped build it ;)\nLewis: Cool, maybe we should write a book about it. What do you think?\nLeandro: Great idea, how hard can it be?!\nThom: I am in!\nLewis: Awesome, let's do it together!\n\"\"\"\nprint(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])","metadata":{"id":"F0qkYCeu-C4s","outputId":"8540ed1d-df09-4e66-c2e3-209bd06d6e56"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion","metadata":{"id":"z6Lag_gu-C4s"}}]}