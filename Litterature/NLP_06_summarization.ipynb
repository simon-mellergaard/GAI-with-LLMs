{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":""},"colab":{"include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/simon-mellergaard/GAI-with-LLMs/blob/main/Litterature/NLP_06_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"colab_type":"text","id":"view-in-github"}},{"cell_type":"markdown","source":"[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/simonmellergaard/notebook82bf2bbae6/edit)","metadata":{}},{"cell_type":"code","source":"# Uncomment and run this cell if you're on Colab or Kaggle\n# !git clone https://github.com/nlp-with-transformers/notebooks.git\n# %cd notebooks\n# from install import *\n# install_requirements(is_chapter6=True)","metadata":{"id":"U5sCYhVI-C3_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide\nfrom utils import *\nsetup_chapter()","metadata":{"id":"ciGv2TxN-C4A","outputId":"9db473ec-71a0-4d48-89ef-c044726228ea"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide\nfrom transformers import pipeline, set_seed","metadata":{"id":"pCo0yaKG-C4B","outputId":"e8a97665-67ef-40d0-fd05-8eeb80b1e80d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Summarization","metadata":{"id":"H4fkiDEo-C4D"}},{"cell_type":"markdown","source":"## The CNN/DailyMail Dataset","metadata":{"id":"dHaqYYpp-C4F"}},{"cell_type":"code","source":"#hide_output\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\nprint(f\"Features: {dataset['train'].column_names}\")","metadata":{"colab":{"referenced_widgets":["437ab47eb9f7412680333b25ff8276b3"]},"id":"uVNC9ciI-C4H","outputId":"ee23b864-c468-41a2-8b05-e45ff19d24a3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = dataset[\"train\"][1]\nprint(f\"\"\"\nArticle (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n\"\"\")\nprint(sample[\"article\"][:500])\nprint(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\nprint(sample[\"highlights\"])","metadata":{"id":"yyOuzRmS-C4J","outputId":"5b0c8168-7c7b-4dae-c6c1-98a3872bd16d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Text Summarization Pipelines","metadata":{"id":"TfHF7LMU-C4L"}},{"cell_type":"code","source":"sample_text = dataset[\"train\"][1][\"article\"][:2000]\n# We'll collect the generated summaries of each model in a dictionary\nsummaries = {}","metadata":{"id":"79L8py9k-C4L"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide_output\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download(\"punkt\")","metadata":{"id":"IbynKL-P-C4N","outputId":"b209fd5b-28f0-4e0d-b9d7-4b65c45fe4d9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"string = \"The U.S. are a country. The U.N. is an organization.\"\nsent_tokenize(string)","metadata":{"id":"VuDcEB0w-C4P","outputId":"e5d67b08-ecf8-40af-e1f1-2fe6eb94db06"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Summarization Baseline\n","metadata":{"id":"r75aYFVB-C4Q"}},{"cell_type":"code","source":"def three_sentence_summary(text):\n    return \"\\n\".join(sent_tokenize(text)[:3])","metadata":{"id":"RZzzdy-B-C4R"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summaries[\"baseline\"] = three_sentence_summary(sample_text)","metadata":{"id":"MzNcZr6W-C4S"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### GPT-2","metadata":{"id":"O4tSoZ-V-C4S"}},{"cell_type":"code","source":"#hide_output\nfrom transformers import pipeline, set_seed\n\nset_seed(42)\npipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\ngpt2_query = sample_text + \"\\nTL;DR:\\n\"\npipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\nsummaries[\"gpt2\"] = \"\\n\".join(\n    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))","metadata":{"id":"MJZdhgZq-C4S"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### T5","metadata":{"id":"uHG9Gw4Z-C4T"}},{"cell_type":"markdown","source":"<img alt=\"T5\" width=\"700\" caption=\"Diagram of T5's text-to-text framework (courtesy of Colin Raffel); besides translation and summarization, the CoLA (linguistic acceptability) and STSB (semantic similarity) tasks are shown\" src=\"https://github.com/nlp-with-transformers/notebooks/blob/main/images/chapter08_t5.png?raw=1\" id=\"T5\"/>","metadata":{"id":"noqZp7Mb-C4T"}},{"cell_type":"code","source":"#hide_output\npipe = pipeline(\"summarization\", model=\"t5-large\")\npipe_out = pipe(sample_text)\nsummaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))","metadata":{"id":"FMp0vHgi-C4T"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### BART","metadata":{"id":"wvRS0OHU-C4T"}},{"cell_type":"code","source":"#hide_output\npipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\npipe_out = pipe(sample_text)\nsummaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))","metadata":{"id":"D-sFpsML-C4T"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### PEGASUS","metadata":{"id":"k6qWTK9s-C4U"}},{"cell_type":"markdown","source":"<img alt=\"pegasus\" width=\"700\" caption=\"Diagram of PEGASUS architecture (courtesy of Jingqing Zhang et al.)\" src=\"https://github.com/nlp-with-transformers/notebooks/blob/main/images/chapter08_pegasus.png?raw=1\" id=\"pegasus\"/>","metadata":{"id":"641ykWFb-C4U"}},{"cell_type":"code","source":"#hide_output\npipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\npipe_out = pipe(sample_text)\nsummaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")","metadata":{"id":"I7ruabL6-C4U"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Comparing Different Summaries","metadata":{"id":"rbVEUFzx-C4U"}},{"cell_type":"code","source":"print(\"GROUND TRUTH\")\nprint(dataset[\"train\"][1][\"highlights\"])\nprint(\"\")\n\nfor model_name in summaries:\n    print(model_name.upper())\n    print(summaries[model_name])\n    print(\"\")","metadata":{"id":"tK55o3Kg-C4U","outputId":"8fd4575b-e913-4a95-a30e-ca2c2774ee3b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Measuring the Quality of Generated Text","metadata":{"id":"7QKWMtHc-C4U"}},{"cell_type":"markdown","source":"### BLEU","metadata":{"id":"3Wnstti2-C4V"}},{"cell_type":"code","source":"# hide_output\nfrom datasets import load_metric\n\nbleu_metric = load_metric(\"sacrebleu\")","metadata":{"id":"y543Vwam-C4V"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nbleu_metric.add(\n    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\nresults[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])","metadata":{"id":"bL7k1ROg-C4X","outputId":"8964ad2e-6a79-42fd-b7ed-25c3c621c422"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bleu_metric.add(\n    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\nresults[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])","metadata":{"id":"LcPkjVP7-C4Y","outputId":"8945d9dd-f95e-4b85-c6fb-cec3ea9d4182"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ROUGE","metadata":{"id":"52f4IYxq-C4a"}},{"cell_type":"code","source":"# hide_output\nrouge_metric = load_metric(\"rouge\")","metadata":{"id":"GUul241G-C4b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reference = dataset[\"train\"][1][\"highlights\"]\nrecords = []\nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n\nfor model_name in summaries:\n    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n    score = rouge_metric.compute()\n    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n    records.append(rouge_dict)\npd.DataFrame.from_records(records, index=summaries.keys())","metadata":{"id":"swks9VbO-C4b","outputId":"58befdfe-7e00-4e70-b1d7-5f2998aa49f9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating PEGASUS on the CNN/DailyMail Dataset","metadata":{"id":"5Bn1K8fC-C4c"}},{"cell_type":"code","source":"# hide\n# ignore this cell it is only to be able to start running the notebook here\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom datasets import load_dataset, load_metric\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ndataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\nrouge_metric = load_metric(\"rouge\", cache_dir=None)\nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]","metadata":{"colab":{"referenced_widgets":["da745498cb9f4dd7b7dbdfed92bb61b2"]},"id":"1JgABy9x-C4c","outputId":"bf01ec12-20c1-4fc4-d541-0a1c37eff34d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_summaries_baseline(dataset, metric,\n                                column_text=\"article\",\n                                column_summary=\"highlights\"):\n    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n    metric.add_batch(predictions=summaries,\n                     references=dataset[column_summary])\n    score = metric.compute()\n    return score","metadata":{"id":"qtaBseXU-C4d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n\nscore = evaluate_summaries_baseline(test_sampled, rouge_metric)\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T","metadata":{"id":"Z-3D2nGV-C4d","outputId":"e881ad29-35d9-43ad-ab70-a7d7779e5476"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef chunks(list_of_elements, batch_size):\n    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\ndef evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n                               batch_size=16, device=device,\n                               column_text=\"article\",\n                               column_summary=\"highlights\"):\n    article_batches = list(chunks(dataset[column_text], batch_size))\n    target_batches = list(chunks(dataset[column_summary], batch_size))\n\n    for article_batch, target_batch in tqdm(\n        zip(article_batches, target_batches), total=len(article_batches)):\n\n        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n                        padding=\"max_length\", return_tensors=\"pt\")\n\n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                         attention_mask=inputs[\"attention_mask\"].to(device),\n                         length_penalty=0.8, num_beams=8, max_length=128)\n\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n                                clean_up_tokenization_spaces=True)\n               for s in summaries]\n        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n\n    score = metric.compute()\n    return score","metadata":{"id":"cwMxxuJc-C4d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_output\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_ckpt = \"google/pegasus-cnn_dailymail\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\nscore = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n                                   model, tokenizer, batch_size=8)\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"id":"1gXjk0r2-C4i","outputId":"a3ec4b9d-3335-488b-8628-05948cfb4a08"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_input\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"id":"Hk966mgD-C4j","outputId":"828ce076-8463-4c20-c862-0d53a88baa62"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training a Summarization Model","metadata":{"id":"I0O0YzY9-C4j"}},{"cell_type":"code","source":"# hide_output\ndataset_samsum = load_dataset(\"samsum\")\nsplit_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n\nprint(f\"Split lengths: {split_lengths}\")\nprint(f\"Features: {dataset_samsum['train'].column_names}\")\nprint(\"\\nDialogue:\")\nprint(dataset_samsum[\"test\"][0][\"dialogue\"])\nprint(\"\\nSummary:\")\nprint(dataset_samsum[\"test\"][0][\"summary\"])","metadata":{"id":"YOV89xC2-C4j"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_input\nprint(f\"Split lengths: {split_lengths}\")\nprint(f\"Features: {dataset_samsum['train'].column_names}\")\nprint(\"\\nDialogue:\")\nprint(dataset_samsum[\"test\"][0][\"dialogue\"])\nprint(\"\\nSummary:\")\nprint(dataset_samsum[\"test\"][0][\"summary\"])","metadata":{"id":"pLQDItem-C4j","outputId":"2ae2dce6-e775-4b64-e143-02c4e19b459c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluating PEGASUS on SAMSum","metadata":{"id":"dJ6Dzidu-C4k"}},{"cell_type":"code","source":"pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\nprint(\"Summary:\")\nprint(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))","metadata":{"id":"YyN8lWZg-C4k","outputId":"c7ec9ce3-747f-4e60-9a54-a427e8cb8fc9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_output\nscore = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n                                   tokenizer, column_text=\"dialogue\",\n                                   column_summary=\"summary\", batch_size=8)\n\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"id":"x-8mSUdb-C4k","outputId":"862283f8-5ea3-4405-fc8b-40d05d84b480"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_input\npd.DataFrame(rouge_dict, index=[\"pegasus\"])","metadata":{"id":"8zqXgffR-C4k","outputId":"d2847a94-05ba-476f-a0cc-547692a905a6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fine-Tuning PEGASUS","metadata":{"id":"pT7NKb3z-C4l"}},{"cell_type":"code","source":"d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\ns_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\naxes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\naxes[0].set_title(\"Dialogue Token Length\")\naxes[0].set_xlabel(\"Length\")\naxes[0].set_ylabel(\"Count\")\naxes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\naxes[1].set_title(\"Summary Token Length\")\naxes[1].set_xlabel(\"Length\")\nplt.tight_layout()\nplt.show()","metadata":{"id":"baIkJh4v-C4l","outputId":"648e38bc-e958-4ae4-c0e1-6e31743988df"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide_output\ndef convert_examples_to_features(example_batch):\n    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n                                truncation=True)\n\n    with tokenizer.as_target_tokenizer():\n        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n                                     truncation=True)\n\n    return {\"input_ids\": input_encodings[\"input_ids\"],\n            \"attention_mask\": input_encodings[\"attention_mask\"],\n            \"labels\": target_encodings[\"input_ids\"]}\n\ndataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n                                       batched=True)\ncolumns = [\"input_ids\", \"labels\", \"attention_mask\"]\ndataset_samsum_pt.set_format(type=\"torch\", columns=columns)","metadata":{"id":"-aTydYAd-C4l"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide_input\n\n#id teacher-forcing\n#alt Decoder input and label alignemt for text generation.\n#caption Decoder input and label alignemt for text generation.\ntext = ['PAD','Transformers', 'are', 'awesome', 'for', 'text', 'summarization']\nrows = []\nfor i in range(len(text)-1):\n    rows.append({'step': i+1, 'decoder_input': text[:i+1], 'label': text[i+1]})\npd.DataFrame(rows).set_index('step')","metadata":{"id":"4li83sJw-C4m","outputId":"87cad435-ac39-454b-f8c2-db89781629c1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\nseq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"id":"kL4CTulF-C4n"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n    weight_decay=0.01, logging_steps=10, push_to_hub=True,\n    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n    gradient_accumulation_steps=16)","metadata":{"id":"rDTnokgj-C4o"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide_output\nfrom huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"colab":{"referenced_widgets":["04f65c507a094c53a28628b65aad0b0b"]},"id":"7JaIPzZh-C4p","outputId":"c535a325-fad3-49ce-e039-1d2b2bcdeee0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_output\ntrainer = Trainer(model=model, args=training_args,\n                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n                  train_dataset=dataset_samsum_pt[\"train\"],\n                  eval_dataset=dataset_samsum_pt[\"validation\"])","metadata":{"id":"d6vftRrT-C4p"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_output\ntrainer.train()\nscore = evaluate_summaries_pegasus(\n    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n    batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[f\"pegasus\"])","metadata":{"id":"gStqGnB4-C4p"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_input\npd.DataFrame(rouge_dict, index=[f\"pegasus\"])","metadata":{"id":"hscueELK-C4q","outputId":"3802ce60-239c-4f0a-c342-9e16940d3e79"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hide_output\ntrainer.push_to_hub(\"Training complete!\")","metadata":{"id":"PgDbZVQ4-C4r","outputId":"7e671eea-c11e-4fa5-efb6-bbb36a3fa38b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Generating Dialogue Summaries","metadata":{"id":"2RozmEBY-C4r"}},{"cell_type":"code","source":"# hide\nimport transformers\ntransformers.logging.set_verbosity_error()","metadata":{"id":"crf5PP6c-C4r"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\nsample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\nreference = dataset_samsum[\"test\"][0][\"summary\"]\npipe = pipeline(\"summarization\", model=\"transformersbook/pegasus-samsum\")\n\nprint(\"Dialogue:\")\nprint(sample_text)\nprint(\"\\nReference Summary:\")\nprint(reference)\nprint(\"\\nModel Summary:\")\nprint(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])","metadata":{"id":"2zYIYE6G-C4s","outputId":"ed1fbf72-ac81-44e6-b3e8-21da45df7d32"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"custom_dialogue = \"\"\"\\\nThom: Hi guys, have you heard of transformers?\nLewis: Yes, I used them recently!\nLeandro: Indeed, there is a great library by Hugging Face.\nThom: I know, I helped build it ;)\nLewis: Cool, maybe we should write a book about it. What do you think?\nLeandro: Great idea, how hard can it be?!\nThom: I am in!\nLewis: Awesome, let's do it together!\n\"\"\"\nprint(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])","metadata":{"id":"F0qkYCeu-C4s","outputId":"8540ed1d-df09-4e66-c2e3-209bd06d6e56"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion","metadata":{"id":"z6Lag_gu-C4s"}}]}