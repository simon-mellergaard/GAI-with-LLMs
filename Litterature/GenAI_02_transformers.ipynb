{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simon-mellergaard/GAI-with-LLMs/blob/main/Litterature/GenAI_02_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/simonmellergaard/genai-02-transformers/edit)"
      ],
      "metadata": {
        "id": "kuquSYtOpsOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers"
      ],
      "metadata": {
        "id": "5zQ9K-Ms-8Qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is a supplement to the Transformers Chapter of the [Hands-On Generative AI with Transformers and Diffusion Models](https://learning.oreilly.com/library/view/hands-on-generative-ai/9781098149239/) book. This notebooks includes:\n",
        "\n",
        "* The code from the book\n",
        "* Additional examples\n",
        "* Exercise solutions."
      ],
      "metadata": {
        "id": "21BxHPqj-8Qt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up by installing various packages:"
      ],
      "metadata": {
        "id": "1Q4fbF6FHKK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install genaibook"
      ],
      "metadata": {
        "id": "e8BwpUBlHGSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import logging\n",
        "\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "kS_un8Xh-8Qu"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Language Model in Action"
      ],
      "metadata": {
        "id": "vUxxHKdz-8Qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizing Text"
      ],
      "metadata": {
        "id": "DZlWCYrf-8Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Use the id of the model you want to use\n",
        "# GPT-2 \"openai-community/gpt2\"\n",
        "# Qwen \"Qwen/Qwen2-0.5B\"\n",
        "# SmolLM \"HuggingFaceTB/SmolLM-135M\"\n",
        "\n",
        "prompt = \"It was a dark and stormy\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
        "input_ids = tokenizer(prompt).input_ids\n",
        "input_ids"
      ],
      "metadata": {
        "id": "lSaZ_SMn-8Qw",
        "outputId": "787bd7af-f222-4e92-f97b-7e2549578555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2132, 572, 264, 6319, 323, 13458, 88]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "for t in input_ids:\n",
        "    print(t, \"\\t:\", tokenizer.decode(t))"
      ],
      "metadata": {
        "id": "VebQiCMj-8Qx",
        "outputId": "d9ec9f8b-dc69-441a-d49e-e8db0a6fa06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2132 \t: It\n",
            "572 \t:  was\n",
            "264 \t:  a\n",
            "6319 \t:  dark\n",
            "323 \t:  and\n",
            "13458 \t:  storm\n",
            "88 \t: y\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting Probabilities"
      ],
      "metadata": {
        "id": "pi708T6f-8Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")"
      ],
      "metadata": {
        "id": "TwtH0F_T-8Qy"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# We tokenize again but specifying the tokenizer that we want it to\n",
        "# return a PyTorch tensor, which is what the model expects,\n",
        "# rather than a list of integers\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model(input_ids)\n",
        "outputs.logits.shape  # An output for each input token"
      ],
      "metadata": {
        "id": "QAlZI7u7-8Qy",
        "outputId": "7f7b3bb0-5428-4148-b145-f768f53dec60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 151936])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_logits = model(input_ids).logits[0, -1]  # The last set of logits\n",
        "final_logits.argmax()  # The position of the maximum"
      ],
      "metadata": {
        "id": "lNLY-wAS-8Q0",
        "outputId": "f4d04f6e-61d8-471a-e487-b3d4abbc775f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3729)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(final_logits.argmax())"
      ],
      "metadata": {
        "id": "B8-qsw_k-8Q0",
        "outputId": "61abcebb-b509-46d8-9bd2-037e73fcfae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' night'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "top10_logits = torch.topk(final_logits, 10)\n",
        "for index in top10_logits.indices:\n",
        "    print(tokenizer.decode(index))"
      ],
      "metadata": {
        "id": "oFE0HBB8-8Q0",
        "outputId": "6f17a6ec-709b-44ff-d4e5-b23e64ffa97f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " night\n",
            " evening\n",
            " day\n",
            " morning\n",
            " winter\n",
            " afternoon\n",
            " Saturday\n",
            " Sunday\n",
            " Friday\n",
            " October\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "top10 = torch.topk(final_logits.softmax(dim=0), 10)\n",
        "for value, index in zip(top10.values, top10.indices):\n",
        "    print(f\"{tokenizer.decode(index):<10} {value.item():.2%}\")"
      ],
      "metadata": {
        "id": "6Vhc0ixi-8Q0",
        "outputId": "ce8d6240-4695-4f04-b693-3b3e5aba928b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " night     88.71%\n",
            " evening   4.30%\n",
            " day       2.19%\n",
            " morning   0.49%\n",
            " winter    0.45%\n",
            " afternoon 0.27%\n",
            " Saturday  0.25%\n",
            " Sunday    0.19%\n",
            " Friday    0.17%\n",
            " October   0.16%\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Text"
      ],
      "metadata": {
        "id": "lGr55H3U-8Q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Greedy Decoding**"
      ],
      "metadata": {
        "id": "9MtMrKQr-8Q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_ids = model.generate(input_ids, max_new_tokens=20)\n",
        "decoded_text = tokenizer.decode(output_ids[0])\n",
        "\n",
        "print(\"Input IDs\", input_ids[0])\n",
        "print(\"Output IDs\", output_ids)\n",
        "print(f\"Generated text: {decoded_text}\")"
      ],
      "metadata": {
        "id": "vMuRXKHV-8Q1",
        "outputId": "ca270006-b418-4005-82a5-25f2d20f92cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs tensor([ 2132,   572,   264,  6319,   323, 13458,    88])\n",
            "Output IDs tensor([[ 2132,   572,   264,  6319,   323, 13458,    88,  3729,    13,   576,\n",
            "         12884,   572,  6319,   323,   279,  9956,   572,  1246,  2718,    13,\n",
            "           576, 11174,   572, 50413,  1495,   323,   279]])\n",
            "Generated text: It was a dark and stormy night. The sky was dark and the wind was howling. The rain was pouring down and the\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beam Search**"
      ],
      "metadata": {
        "id": "aAAHnUdp-8Q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beam_output = model.generate(\n",
        "    input_ids,\n",
        "    num_beams=5,\n",
        "    max_new_tokens=30,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(beam_output[0]))"
      ],
      "metadata": {
        "id": "hpp7pS5O-8Q1",
        "outputId": "3498b505-4542-4863-d413-71b77ce12adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy night. The wind was howling, and the rain was pouring down. The sky was dark and gloomy, and the air was filled with the\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beam search with repetition penalty**"
      ],
      "metadata": {
        "id": "EQ3Yv1M4-8Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beam_output = model.generate(\n",
        "    input_ids,\n",
        "    num_beams=5,\n",
        "    repetition_penalty=2.0,\n",
        "    max_new_tokens=38,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(beam_output[0]))"
      ],
      "metadata": {
        "id": "9_8PRF1Y-8Q2",
        "outputId": "6e2c5941-144f-4f71-adca-81e0b44d31a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy night. The sky was filled with thunder and lightning, and the wind howled in the distance. It was raining cats and dogs, and the streets were covered in puddles of water.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling**"
      ],
      "metadata": {
        "id": "r0VKCNvQ-8Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "# Setting the seed ensures we get the same results every time we run this code\n",
        "set_seed(70)\n",
        "\n",
        "sampling_output = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_new_tokens=34,\n",
        "    top_k=0,  # We'll come back to this parameter\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(sampling_output[0]))"
      ],
      "metadata": {
        "id": "TIXO8zTZ-8Q2",
        "outputId": "79cb4a2d-565f-414b-e125-95c4f7b2c968",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy night.Six pots of moisture laced the sky，pulling back fog and issuing a shared smell.\n",
            "16 km away they were cleaned and brought to her attention by\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling with different `temperature`s**"
      ],
      "metadata": {
        "id": "k8cCSOfL-8Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_output = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    max_new_tokens=40,\n",
        "    top_k=0,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(sampling_output[0]))"
      ],
      "metadata": {
        "id": "3If19lAV-8Q3",
        "outputId": "076f7583-cc8c-4746-ab92-b022eeb1723f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy night in the hills of the Sierra Madre. The rain was heavy and the wind howled. The thunder was deafening and the lightning was a sight to behold. The sky was filled with clouds\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_output = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    temperature=0.001,\n",
        "    max_new_tokens=40,\n",
        "    top_k=0,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(sampling_output[0]))"
      ],
      "metadata": {
        "id": "h4jMutKr-8Q3",
        "outputId": "b0c3cf99-1a83-40c3-9783-f5fa11cc76c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy night. The sky was dark and the wind was howling. The rain was pouring down and the lightning was flashing. The sky was dark and the wind was howling. The rain was pouring down\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_output = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    temperature=3.0,\n",
        "    max_new_tokens=40,\n",
        "    top_k=0,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(sampling_output[0]))"
      ],
      "metadata": {
        "id": "tnbPXJSL-8Q3",
        "outputId": "71762820-c5a3-45ec-c98b-028201daf707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy wheahkan exhilar swords seasHe Bd HibernateOthers Турية freed deploy Exhibition strtotimering finishing invadingmarker honoringЩ Uniform barracks Joan onde abbrev Mg/get铟 railway sticking Ant municipalities Kgforeach covering kin grown tacticalButtonText\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling with `top_k`**"
      ],
      "metadata": {
        "id": "26lQ3kXP-8Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_output = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_new_tokens=40,\n",
        "    top_k=10,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(sampling_output[0]))"
      ],
      "metadata": {
        "id": "l40R-MO7-8Q4",
        "outputId": "042689be-28c1-47b0-e77f-0bb4c5c487f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy night in the small town of Ketchum in 1989. It had been a cold and wet January. A group of 33 college students were gathered to go hunting for deer\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top-p sampling**"
      ],
      "metadata": {
        "id": "iaXe14Qn-8Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_output = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_new_tokens=40,\n",
        "    top_p=0.94,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(sampling_output[0]))"
      ],
      "metadata": {
        "id": "hUF0ATNn-8Q4",
        "outputId": "140f2890-6ecb-4afa-ab9c-f8b9bebe4d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a dark and stormy night in early July 2017. Despite the stormy weather the 2017 edition of the International FFA National High School Competition was successful, as 12 teams from\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot Classification"
      ],
      "metadata": {
        "id": "1jQ_3TNH-8Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Book code"
      ],
      "metadata": {
        "id": "P9YtN4NR-8Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the token IDs for the words ' positive' and ' negative'\n",
        "# (note the space before the words)\n",
        "tokenizer.encode(\" positive\"), tokenizer.encode(\" negative\")"
      ],
      "metadata": {
        "id": "BYigWFml-8Q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b198fd-cd3c-42a5-a737-f6fda859fa46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6785], [8225])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "def score(review):\n",
        "    \"\"\"Predict whether it is positive or negative\n",
        "\n",
        "    This function predicts whether a review is positive or negative\n",
        "    using a bit of clever prompting. It looks at the logits for the\n",
        "    tokens ' positive' and ' negative', and returns the label\n",
        "    with the highest score.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Question: Is the following review positive or\n",
        "negative about the movie?\n",
        "Review: {review} Answer:\"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids  # <1>\n",
        "    final_logits = model(input_ids).logits[0, -1]  # <2>\n",
        "    if final_logits[6785] > final_logits[8225]:  # <3>\n",
        "        print(\"Positive\")\n",
        "    else:\n",
        "        print(\"Negative\")"
      ],
      "metadata": {
        "id": "SgmAz4K3-8Q5"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "score(\"This movie was terrible!\")"
      ],
      "metadata": {
        "id": "pBoJZtmv-8Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084ac2ff-e53f-4077-aa60-be18d754ec9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "score(\"That movie was great!\")"
      ],
      "metadata": {
        "id": "syEhQvqY-8Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3de7d0c-d08f-4f10-ab56-5caa6fff58b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "score(\"A complex yet wonderful film about the depravity of man\")  # A mistake"
      ],
      "metadata": {
        "id": "gwf-WopS-8Q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae571c51-230a-4561-ada1-ecf665635e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Suplementary material (not in the book)"
      ],
      "metadata": {
        "id": "BGv8Oy8--8Q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section shows how to use a pre-trained generative model to perform classification via zero-shot classification. We'll use a dataset of labeled reviews and measure the confusion matrix. A confusion matrix serves as a table summarizing a model's performance, depicting counts of true positive, true negative, false positive, and false negative predictions. Rows indicate actual (ground truth) classes, while columns indicate predicted classes. Analyzing this matrix provides insights into the model's strengths and weaknesses in distinguishing between specific classes."
      ],
      "metadata": {
        "id": "OXJiYnB4-8Q_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the `Qwen/Qwen2-0.5B` model and its tokenizer."
      ],
      "metadata": {
        "id": "GYgnDUG_-8Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from genaibook.core import get_device\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# get device function:\n",
        "# def get_device(cuda_ordinal=None):\n",
        "#     if torch.cuda.is_available():\n",
        "#         return torch.device(\"cuda\", cuda_ordinal)\n",
        "#     if torch.backends.mps.is_available():\n",
        "#         return torch.device(\"mps\")\n",
        "#     return torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "device = get_device()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\").to(device)"
      ],
      "metadata": {
        "id": "3wxCxU5s-8RA"
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we define our `score` function just as in the book, but with some key differences:\n",
        "\n",
        "* we use 1 (`positive`) and 0 (`negative`),\n",
        "* we receive a sample so we can use the `datasets` library. You can use this as a dictionary with the review being accessible with `sample[\"text\"]`,\n",
        "* we add a new column, `pred`, which contains the 0 or 1 from the model.\n",
        "* we add `truncation=True` to the `tokenizer` call. Truncation is needed as `score` will be called with a batch of samples, and we need to ensure that all samples have the same length. We'll explain in future chapters why this is needed, but for now, just remember that it's necessary when working with batches of samples."
      ],
      "metadata": {
        "id": "vtsJ4dGS-8RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\" positive\"), tokenizer.encode(\" negative\")"
      ],
      "metadata": {
        "id": "UatsrFsw-8RA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9991b50-b32d-4f0a-d36e-5687907e145d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6785], [8225])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "def score(sample):\n",
        "    \"\"\"Given a review, predict whether it is positive or negative using a bit of clever prompting\"\"\"\n",
        "    prompt = f\"Question: Is the following review positive or negative about the movie?\\nReview: {sample['text']} Answer:\"\n",
        "    input_ids = tokenizer(\n",
        "        prompt, truncation=True, return_tensors=\"pt\"\n",
        "    ).input_ids.to(device)\n",
        "    final_logits = model(input_ids).logits[0, -1]\n",
        "    if final_logits[6785] > final_logits[8225]:\n",
        "        sample[\"pred\"] = 1\n",
        "    else:\n",
        "        sample[\"pred\"] = 0\n",
        "    return sample"
      ],
      "metadata": {
        "id": "vRNzr80B-8RA"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "# New prompt\n",
        "def score(sample):\n",
        "    \"\"\"Given a review, predict whether it is positive or negative using a bit of clever prompting\"\"\"\n",
        "    prompt = f\"Question: Is this sentence positive or negative?\\nReview: {sample['text']} Answer:\"\n",
        "    input_ids = tokenizer(\n",
        "        prompt, truncation=True, return_tensors=\"pt\"\n",
        "    ).input_ids.to(device)\n",
        "    final_logits = model(input_ids).logits[0, -1]\n",
        "    if final_logits[6785] > final_logits[8225]:\n",
        "        sample[\"pred\"] = 1\n",
        "    else:\n",
        "        sample[\"pred\"] = 0\n",
        "    return sample"
      ],
      "metadata": {
        "id": "qKgy7NOGKb_0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score({\"text\": \"This movie was terrible!\"})"
      ],
      "metadata": {
        "id": "nthla9Mo-8RA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c914da89-cc85-4002-ca85-fb30965c0fff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'This movie was terrible!', 'pred': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the [IMDB](https://huggingface.co/datasets/imdb) dataset, which contains 25,000 rows of labeled reviews. We'll use the `datasets` library to load the dataset and load the `train` split."
      ],
      "metadata": {
        "id": "mOot17Hh-8RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"imdb\")[\"train\"]"
      ],
      "metadata": {
        "id": "oLFXT34u-8RA"
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": [
        "For fast iteration, we'll just use 1000 random samples from the dataset. We'll `shuffle` the dataset and then take the first 1000 samples."
      ],
      "metadata": {
        "id": "UNKSOWZ4-8RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_dataset = dataset.shuffle(seed=42)\n",
        "small_dataset = shuffled_dataset.select(range(1000))"
      ],
      "metadata": {
        "id": "GtH2NIV2-8RB"
      },
      "outputs": [],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can use the `score` function to predict the sentiment of the reviews and compare the predictions with the actual labels."
      ],
      "metadata": {
        "id": "H-9_YdtW-8RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_dataset = small_dataset.map(score)"
      ],
      "metadata": {
        "id": "_1mm_IYz-8RB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "updated_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqnBQrDpMqdN",
        "outputId": "970bc2c5-c3f9-4b93-cfd6-a2e2a5b219c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'pred'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the `evaluate` library to obtain the confusion matrix. A confusion matrix serves as a table summarizing a model's performance, depicing counts of true positive, true negatives, false positive, and false negative predictions. Rows indicate actual (label) classes, while columns indicate predicted classes. Analyzing this matrix provides insights into the model's strengths and weaknesses in distinguishing between classes. The fine-tune LLM chapter dives into this metric."
      ],
      "metadata": {
        "id": "Y5LMJHdW-8RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "confusion_matrix = evaluate.load(\"confusion_matrix\")\n",
        "cm = confusion_matrix.compute(\n",
        "    references=updated_dataset[\"label\"],\n",
        "    predictions=updated_dataset[\"pred\"],\n",
        ")\n",
        "cm"
      ],
      "metadata": {
        "id": "Hztz-R2--8RB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d570f08-39b2-432c-d70b-d8fb5101aaa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'confusion_matrix': array([[502,  10],\n",
              "        [165, 323]])}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm[\"confusion_matrix\"],\n",
        "    display_labels=[\"negative\", \"positive\"],\n",
        ")\n",
        "disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "\n",
        "plt.title(\"Normalized confusion matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3wn4vW2H-8RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "26d56973-2625-4079-8529-0807db6ca393"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# new cm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm[\"confusion_matrix\"],\n",
        "    display_labels=[\"negative\", \"positive\"],\n",
        ")\n",
        "disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "\n",
        "plt.title(\"Normalized confusion matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "vBvR3mPYKlqO",
        "outputId": "20edeb47-fe98-4ce2-f43a-2e4fc796e16e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do we get out of these results?\n",
        "\n",
        "* The model does not perform amazingly well. There are many false negatives.\n",
        "* The model is very good identifying most negative reviews, but unfortunately marks many positive reviews as negative.\n",
        "\n",
        "Finally, we can also convert the dataset to a Pandas `DataFrame` and explore the data directly. Here is a starting point"
      ],
      "metadata": {
        "id": "RkhmRDxD-8RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = updated_dataset.to_pandas()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "363pZ2wL-8RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5986b6ad-a20b-4860-e28d-0545486b6e4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  pred\n",
              "0  There is no relation at all between Fortier an...      1     0\n",
              "1  This movie is a great. The plot is very true t...      1     1\n",
              "2  George P. Cosmatos' \"Rambo: First Blood Part I...      0     0\n",
              "3  In the process of trying to establish the audi...      1     0\n",
              "4  Yeh, I know -- you're quivering with excitemen...      0     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ea96a3-04c4-4d2d-81d4-3e6b8b19c04b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There is no relation at all between Fortier an...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This movie is a great. The plot is very true t...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>George P. Cosmatos' \"Rambo: First Blood Part I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the process of trying to establish the audi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Yeh, I know -- you're quivering with excitemen...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ea96a3-04c4-4d2d-81d4-3e6b8b19c04b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1ea96a3-04c4-4d2d-81d4-3e6b8b19c04b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1ea96a3-04c4-4d2d-81d4-3e6b8b19c04b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89acd332-5548-42ec-b96e-b0db41efd8f3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89acd332-5548-42ec-b96e-b0db41efd8f3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89acd332-5548-42ec-b96e-b0db41efd8f3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Hitokiri (which translates roughly as \\\"assassination\\\"), a/k/a \\\"Tenchu\\\" which translates roughly as \\\"divine punishment\\\") showcases Hideo Gosha at the top of his form. Do NOT miss this one, or Gosha's other classic, Goyokin! Hitokiri is not only one of Gosha's best films, it's one of the best \\\"samurai/chambara\\\" films ever made, and perhaps one of the best Japanese films ever exported.<br /><br />Be warned, all of the intricate plot details in Hitokiri can be a little hard to follow for those unfamiliar with 19th century Japanese history. Even so, the underlying human drama is obvious and open to all viewers. As per the norm for Gosha, Hitokiri provides yet another variation on his traditional theme of \\\"loyalty to one's lord\\\" vs. \\\"doing the right thing\\\". However, Gosha develops his favorite theme with such sophistication, that it's really _the_ movie to see (along with Goyokin, of course).<br /><br />I suppose it breaks down like this: If you want a simpler, more action-oriented tale, you might want to see Goyokin. However, if you want a more thoughtful, multilayered (albeit grim) drama, see this one.<br /><br />(OK, OK, essentially, the historical backdrop is a massive power grap between many different samurai clans who are either (1) working to reform, yet retain, the Tokugawa Shogunate, and (2) those who are trying to install the Emperor Meiji as the supreme ruler of Japan. Of course, those clans working \\\"for\\\" Emperor Meiji were often less interested in \\\"reforming\\\" Japan than in ensuring their own clan more power in the \\\"new world order\\\". Ironically, the entire feudal system was officially abolished as one of the first reforms of the Meiji government. It's ironic twists like this -- Gosha's big on irony -- that make the entire plot all the more bittersweet.)<br /><br />What distinguishes \\\"Hitokiri\\\" from Gosha's other movies is Gosha's mature sense of cinematography. Every shot is thoughtfully composed, and (much like Kubrick's Barry Lyndon) each frame of the movie could hold its own as a still composition. Of course, this is typical Gosha. Hitokiri really stands out with stunning backdrops, including(as with Goyokin) many riveting seascapes. Just watch the opening sequence, and you're hooked! Make no mistake, this is no English period piece: Hitokiri is extremely violent (don't say you weren't warned).<br /><br />What else, other than cool camera work, makes Hitokiri stand out? The performances seem (to me) a bit more subtle in this one. Katsu Shintaro (of Zatoichi/Hanzo the Razor fame) turns in a star performance as the conflicted protagonist/antihero, Okada Izo. Katsu manages to instill humanity to a character that seems almost more wild animal than villain. Throughout the movie, you're never quite sure if you're engaged or revolted by Okada's character. At the same time, Katsu's portrayal of Okada's ravenous hunger for respect, and his later pathetic attempts at redemption, seem so human that you can't help but feel empathy/sympathy. Of course, after seeing Nakadai Tatsuya play the tortured hero in \\\"Goyokin\\\", it's great to see him play such a ruthless villain in \\\"Hitokiri\\\". He's just perfect, there's nothing more to say!<br /><br />As a final note, perhaps more interesting to buffs than to casual fans, don't miss the last screen appearance of Mishima Yukio (yes, the closeted gay right-wing ultranationalist novelist who committed suicide by seppuku before the crowd of jeering Japanese military personnel he \\\"kidnapped\\\" in 1970, and had a movie on his life and work made by Paul Schrader), who actually does a pretty solid job of portraying the honorable (for an assassin) Shinbei Tanaka.\",\n          \"This one grew on me. I love the R.D. Burman music and in spite of the cruder elements of the story I found much to be moved by as I kept re-watching the movie. The brother-sister plot line is powerful, I thought; there's also more probably obligatory stuff, like bar fights, a loony crime story, etc. that are just distracting. (Though not unfunny from a certain point of view.) Also the English translation is definitely by someone for whom it was a bit of a stretch, and as loony as it is I am grateful to him for doing it.<br /><br />Like many of the Bollywood movies I've seen, this one is melodramatic and opera-like, including here notably a song sung first by a little boy to cheer up his abused and unhappy sister, and then the same song sung 12 or so years later by the man who has travelled to Kathmandu seeking to re-connect with this girl, grown up and troubled (she had been told her brother and mother were dead), numbing her pain with drugs.<br /><br />A super thing about this 1971 movie is that it is about the hippie movement, which brought hordes of seekers to India, from an Indian point of view, that sees them as people driven to India by a spiritual hunger aroused by the failings of their own societies, but nonetheless, in India, living only for the pleasures of the moment. The hippie singing-dancing-drugging scenes are truly wonderful, and accurate in their tone (I'm old enough to remember), and I feel pretty sure that the masses of young white zoned-out kids are actual hippie extras, as I remember hearing about kids on the caravan to the East getting this kind of work in Bollywood.<br /><br />(It is not about the actual Hare Krishna movement, though the movie hippies sing a Krishna/Rama chant, as do a group of actual Indian devotees, unrelated to the hippies, in the opening scene of the movie.)<br /><br />~Virginia\",\n          \"Nacho Vigalondo is very famous in Spain. He is a kind of bad showman who can make you feel sick... Very embarrassing. Nacho had made some commercials in TV, I remember one in which Nacho was looking for Paul Mc Carney around Madrid (the commercial was about a Mc Carney CD collection). <br /><br />This little movie is like a Nacho's commercial: bad storyline, bad directing, and awful performances. I can't believe that a disgusting movie like this was in The Kodak Theater. Poor Oscar...<br /><br />Nacho could made this movie because of his wife, the producer of this 7:35, a woman very well connected with Spanish TV business men.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now it's your turn**. Experiment with tweaking the prompt to improve the model performance. What's the best confusion matrix you can achieve? What if you try another model?"
      ],
      "metadata": {
        "id": "_NKoT01p-8RC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-Shot Generation"
      ],
      "metadata": {
        "id": "wBIvKdVX-8RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We load the model in CPU again for this section for simplicity\n",
        "# but feel free to keep in GPU if you prefer.\n",
        "# Note: you need to move all the data to the device as well.\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\")"
      ],
      "metadata": {
        "id": "b80A-3H_-8RD"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\\\n",
        "Translate English to Spanish:\n",
        "\n",
        "English: I do not speak Spanish.\n",
        "Spanish: No hablo español.\n",
        "\n",
        "English: See you later!\n",
        "Spanish: ¡Hasta luego!\n",
        "\n",
        "English: Where is a good restaurant?\n",
        "Spanish: ¿Dónde hay un buen restaurante?\n",
        "\n",
        "English: What rooms do you have available?\n",
        "Spanish: ¿Qué habitaciones tiene disponibles?\n",
        "\n",
        "English: I like soccer\n",
        "Spanish:\"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "output = model.generate(\n",
        "    inputs,\n",
        "    max_new_tokens=10,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "id": "wvPxVSwP-8RD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade4038e-1322-4b6f-a63f-1bc09541968a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate English to Spanish:\n",
            "\n",
            "English: I do not speak Spanish.\n",
            "Spanish: No hablo español.\n",
            "\n",
            "English: See you later!\n",
            "Spanish: ¡Hasta luego!\n",
            "\n",
            "English: Where is a good restaurant?\n",
            "Spanish: ¿Dónde hay un buen restaurante?\n",
            "\n",
            "English: What rooms do you have available?\n",
            "Spanish: ¿Qué habitaciones tiene disponibles?\n",
            "\n",
            "English: I like soccer\n",
            "Spanish: Me gusta el fútbol\n",
            "\n",
            "English:\n"
          ]
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Models Genealogy"
      ],
      "metadata": {
        "id": "nxvgVTzd-8RD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder-only Models"
      ],
      "metadata": {
        "id": "CgPpdIBn-8RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_masker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "fill_masker(\"The [MASK] is made of milk.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1m1-SiA-8RE",
        "outputId": "224a6702-8682-4ae8-a4be-a46457b6d3f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.19546644389629364,\n",
              "  'token': 9841,\n",
              "  'token_str': 'dish',\n",
              "  'sequence': 'the dish is made of milk.'},\n",
              " {'score': 0.12907548248767853,\n",
              "  'token': 8808,\n",
              "  'token_str': 'cheese',\n",
              "  'sequence': 'the cheese is made of milk.'},\n",
              " {'score': 0.10590681433677673,\n",
              "  'token': 6501,\n",
              "  'token_str': 'milk',\n",
              "  'sequence': 'the milk is made of milk.'},\n",
              " {'score': 0.04112086072564125,\n",
              "  'token': 4392,\n",
              "  'token_str': 'drink',\n",
              "  'sequence': 'the drink is made of milk.'},\n",
              " {'score': 0.0371234267950058,\n",
              "  'token': 7852,\n",
              "  'token_str': 'bread',\n",
              "  'sequence': 'the bread is made of milk.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Power of Pre-training"
      ],
      "metadata": {
        "id": "L_Nkx1A0-8RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The key Insights of Transformers\n"
      ],
      "metadata": {
        "id": "98v-S9gH-8RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        ")\n",
        "classifier(\"This movie is disgustingly good !\")"
      ],
      "metadata": {
        "id": "e-OjQdz2-8RE",
        "outputId": "4ed08a0f-17b5-46eb-a539-613c3a741422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998536109924316}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations\n"
      ],
      "metadata": {
        "id": "TF0f4C5d-8RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"This man works as a [MASK] during summer.\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK] during summer.\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "id": "Y7ZkCbcZ-8RF",
        "outputId": "627f13f9-12cf-4da9-ab4f-de3061bb56b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['farmer', 'carpenter', 'gardener', 'fisherman', 'miner']\n",
            "['maid', 'nurse', 'servant', 'waitress', 'cook']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beyond Text"
      ],
      "metadata": {
        "id": "JKbjiBkR-8RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "from genaibook.core import SampleURL\n",
        "\n",
        "# Download an image and load it with the PIL library\n",
        "url = SampleURL.CatExample\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image"
      ],
      "metadata": {
        "id": "FQDFEDMV-8RG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"zero-shot-image-classification\", model=\"openai/clip-vit-base-patch32\"\n",
        ")\n",
        "labels = [\"cat\", \"dog\", \"zebra\"]\n",
        "pipe(image, candidate_labels=labels)\n"
      ],
      "metadata": {
        "id": "RjH0Aq7L-8RG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solutions\n",
        "\n",
        "A big part of learning is putting your knowledge into practice. We strongly suggest not looking at the answers before taking a serious stab at it. Scroll down for the answers."
      ],
      "metadata": {
        "id": "I1YWS-fV-8RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Time: Using LMs to Generate Text\n",
        "\n",
        "This is the solution for the project. Here we'll implement a `generate` function which supports sampling, `top_k`, and greedy search."
      ],
      "metadata": {
        "id": "iE5Q-xCT-8RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "SDDssYqv-8RH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def generate(\n",
        "    model, tokenizer, input_ids, max_length=50, do_sample=False, top_k=0\n",
        "):\n",
        "    \"\"\"Generate a sequence that starts with `input_ids` without using model.generate().\n",
        "\n",
        "    Args:\n",
        "        model (transformers.PreTrainedModel): The model to use for generation.\n",
        "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to use for generation.\n",
        "        input_ids (torch.Tensor): The input IDs\n",
        "        max_length (int, optional): The maximum length of the sequence. Defaults to 50.\n",
        "        do_sample (bool, optional): Whether to use sampling. Defaults to False.\n",
        "        top_k (int, optional): The number of tokens to sample from. Defaults to 0.\n",
        "    \"\"\"\n",
        "    current_length = input_ids.size(1)  # Current sequence length\n",
        "\n",
        "    for _ in range(max_length - current_length):\n",
        "        # Pass the current sequence through the model\n",
        "        outputs = model(input_ids)\n",
        "\n",
        "        # Get logits for the last token in the output\n",
        "        next_token_logits = outputs.logits[:, -1, :]\n",
        "\n",
        "        if do_sample:\n",
        "            if top_k > 0:\n",
        "                # Apply Top-K filtering\n",
        "                # Get the indices of the top_k logits\n",
        "                top_k_logits, _ = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "                # Get the smallest token from the top_k logits\n",
        "                min_top_k_value = top_k_logits[:, -1].unsqueeze(-1)\n",
        "\n",
        "                # Set values smaller than the smallest top_k value to -infinity (probability 0)\n",
        "                next_token_logits = torch.where(\n",
        "                    next_token_logits < min_top_k_value,\n",
        "                    torch.tensor(float(\"-inf\")),\n",
        "                    next_token_logits,\n",
        "                )\n",
        "\n",
        "            # Apply softmax to convert logits to probabilities for sampling\n",
        "            probs = F.softmax(next_token_logits, dim=-1)\n",
        "            # Sample the next token from the distribution probability\n",
        "            next_token_id = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            # Greedy decoding: choose the token with highest probability\n",
        "            next_token_id = torch.argmax(\n",
        "                next_token_logits, dim=-1, keepdim=True\n",
        "            )\n",
        "\n",
        "        # Append predicted token to the input sequence\n",
        "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
        "\n",
        "        # If the end of sequence token is generated, stop\n",
        "        if next_token_id == tokenizer.eos_token_id:\n",
        "            break\n",
        "    return tokenizer.decode(input_ids.squeeze(), skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "pM6EPwrR-8RI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"It was a dark and stormy\", return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "76Y1R4IU-8RI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first try greedy decoding. As it's deterministic, this should give you the same content as in Chapter 2, which was\n",
        "\n",
        "> It was a dark and stormy night. The wind was blowing, and the clouds were falling. The wind was blowing, and the"
      ],
      "metadata": {
        "id": "tMkLLHvU-8RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate(gpt2, tokenizer, input_ids, do_sample=False)"
      ],
      "metadata": {
        "id": "BVLQry4k-8RI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now try sampling with `top_k`"
      ],
      "metadata": {
        "id": "vA1oaIi9-8RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate(gpt2, tokenizer, input_ids, do_sample=True, top_k=10)"
      ],
      "metadata": {
        "id": "pGksPEiD-8RI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises\n",
        "\n",
        "**1. What's the role of the attention mechanism in text generation?**\n",
        "\n",
        "The attention mechanism in text generation allows the model to focus on different parts of the input sequence when producing each token in the output sequence. It helps the model capture long-range dependencies and relationships between words.\n",
        "\n",
        "\n",
        "**2. In which cases would a character-based tokenizer be preferred?**\n",
        "\n",
        "A character-based tokenizer might be preferred in cases where the language involves specific characters, symbols, or emojis that carry meaning. For example, in Chinese, each character carries more information than a character in a Latin language.\n",
        "\n",
        "\n",
        "**3. What happens if you use a tokenizer different from the one used with the model?**\n",
        "\n",
        "Using a different tokenizer can cause a tokenizer mismatch, leading to inconsistencies in tokenization. This misalignment can result in unexpected or incorrect model outputs.\n",
        "\n",
        "**4. What's the risk of using `no_repeat_ngram_size` when doing generation? (Hint: Think of city names.)**\n",
        "\n",
        "If you use a `no_repeat_ngram_size=3`, the \"New York City\" string will only be generated once. If you're using a generative model to generate a story in NYC, using this penalty will severily hurt it!\n",
        "\n",
        "**5. What would happen if you combine Beam-search and sampling?**\n",
        "\n",
        "With beam search, we maintain the `k` best sequences at each timestep. Instead of determinisitcally choosing the top `k` sequences based on the score, we use a probabilistic element and sample the next token from the probability distribution.\n",
        "\n",
        "This can lead to increased diversity (no repetitive outputs of Beam-search), improved quality (no unpredictable outputs of sampling), and a balance between the two. However, it can require more computational resources due to the increased number of sequences to maintain and sample from.\n",
        "\n",
        "**6. Imagine you're using a LLM that generates code in a code editor by doing sampling. What would be more convenient? A low temperature or a high temperature?**\n",
        "\n",
        "In code generation, a low temperature is more convenient as it generates more deterministic and conservative code, adhering to common patterns and reducing the risk of errors. A high temperature would introduce more randomness and could result in unconventional or less reliable code. Therefore, a low temperature is typically preferred.\n",
        "\n",
        "\n",
        "**7. What’s the importance of fine-tuning, and why is it different from zero-shot generation?**\n",
        "\n",
        "Fine-tuning is crucial for adapting a pre-trained language model to specific tasks or domains. It allows the model to learn task-specific nuances and improves performance on targeted applications. This differs from zero-shot generation, where the model is used without task-specific training.\n",
        "\n",
        "\n",
        "**8. Explain the differences and applications of encoder, decoder, and encoderdecoder transformers.**\n",
        "\n",
        "* **Encoder**: Specialized in processing input sequences and extracting meaningful representations. It's commonly used for tasks like classification, sentiment analysis, and document embeddings. Examples include BERT and RoBERTa.\n",
        "* **Decoder**: Specialized in generating output sequences based on given input. It's often used for text generation tasks. Examples include GPT-2 and T5.\n",
        "* **Encoder-Decoder**: Combines both an encoder and a decoder. The encoder processes the input sequence into a set of representations, which the decoder then uses to generate an output sequence. It's ideal for sequence-to-sequence tasks such as machine translation, text summarization, and question answering. Examples include BART and T5."
      ],
      "metadata": {
        "id": "CYCD__yr-8RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenges\n",
        "\n",
        "**9. Summarization. Use a summarization model (you can do `pipeline(\"summarization)`) to generate summaries of a paragraph. How does it compare with the results of using zero-shot? Can it be beaten by providing few-shot examples?**"
      ],
      "metadata": {
        "id": "HrXim4zS-8RJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first solve this using a summarization model. We'll use a default model, but note that it's a small model from 2020. The results might not be as good as the latest or larger models."
      ],
      "metadata": {
        "id": "34JYXL38-8RJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")"
      ],
      "metadata": {
        "id": "eONrAHGJ-8RJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "long_text = \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pc-5acj2-8RJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer(long_text)"
      ],
      "metadata": {
        "id": "fN0hc5jZ-8RJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now try with a text generation model."
      ],
      "metadata": {
        "id": "ZYBSE_su-8RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\")"
      ],
      "metadata": {
        "id": "NFMmnalW-8RK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_zero_shot(long_text):\n",
        "    zero_shot = generator(\n",
        "        f\"{long_text}.\\\\n Summary:\\\\n\",\n",
        "        return_full_text=False,\n",
        "        max_length=350,\n",
        "    )\n",
        "\n",
        "    return zero_shot"
      ],
      "metadata": {
        "id": "-HSMB1JS-8RK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_with_zero_shot(long_text)"
      ],
      "metadata": {
        "id": "lBd4gzrN-8RK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you achieve better results by improving the prompt or adding some examples to it?"
      ],
      "metadata": {
        "id": "dJrzh7Wf-8RK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Sentiment Analysis. In the zero-shot supplementary material, we calculate some metrics using zero-shot classification. Explore using the `distilbert-base-uncased-finetuned-sst-2-english` encoder model that can do sentiment analysis. What results do you get?**\n",
        "\n",
        "Let's first recall how to use this model. We can either use the `pipeline(\"text-classification\")` approach, or load the model directly with `AutoModel`, which would require handling the tokenization ourselves. We'll want to use `truncation` just as in the zero-shot example above. We begin loading the model and tokenizer. Note that we use `AutoModelForSequenceClassification` to make sure to load the classification layer as well."
      ],
      "metadata": {
        "id": "LYfPQpUX-8RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "fy5C2RdR-8RK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the output with a specific example."
      ],
      "metadata": {
        "id": "VEowpN4W-8RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\n",
        "    \"This movie was terrible!\", truncation=True, return_tensors=\"pt\"\n",
        ").input_ids\n",
        "classifier_output = model(input_ids)\n",
        "classifier_output"
      ],
      "metadata": {
        "id": "3EtWxVRK-8RK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is two logits, which tell us that the first class is more likely than the second. Programmatically, we can do an `argmax` over the `logits` tensor to get the index of the highest value."
      ],
      "metadata": {
        "id": "ozI9gjbL-8RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_id = classifier_output.logits.argmax().item()\n",
        "predicted_class_id"
      ],
      "metadata": {
        "id": "wnOrzZO_-8RL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To which class does the 0 correspond to? Using the model configuration `id2label`, we can obtain the corresponding class"
      ],
      "metadata": {
        "id": "6r-vnbUt-8RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label"
      ],
      "metadata": {
        "id": "EM7cw5Rs-8RL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "And using the model configuration, we can get which label correspond to that id."
      ],
      "metadata": {
        "id": "jSI96Qvi-8RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label[predicted_class_id]"
      ],
      "metadata": {
        "id": "J_GmuCUm-8RL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's wrap this in a function"
      ],
      "metadata": {
        "id": "-MxQndKI-8RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_with_classifier(sample):\n",
        "    \"\"\"Given a review, predict whether it is positive or negative\"\"\"\n",
        "    input_ids = tokenizer(\n",
        "        sample[\"text\"], truncation=True, return_tensors=\"pt\"\n",
        "    ).input_ids\n",
        "    classifier_output = model(input_ids)\n",
        "    sample[\"pred\"] = classifier_output.logits.argmax().item()\n",
        "\n",
        "    return sample"
      ],
      "metadata": {
        "id": "3YHH-yta-8RM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "score_with_classifier({\"text\": \"This movie was terrible!\"})"
      ],
      "metadata": {
        "id": "7DGtfk54-8RM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "updated_dataset = small_dataset.map(score_with_classifier)\n",
        "updated_dataset"
      ],
      "metadata": {
        "id": "UKNO7wNt-8RM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix.compute(\n",
        "    references=updated_dataset[\"label\"], predictions=updated_dataset[\"pred\"]\n",
        ")\n",
        "cm"
      ],
      "metadata": {
        "id": "D23AuCq--8RM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm[\"confusion_matrix\"],\n",
        "    display_labels=[\"negative\", \"positive\"],\n",
        ")\n",
        "disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "\n",
        "plt.title(\"Normalized confusion matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ict7CyHI-8RM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impressive! This sentiment analysis classifier performs much better than the zero-shot setup, specially for positive reviews which were being misclassified as negative."
      ],
      "metadata": {
        "id": "hDf4HPw3-8RM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Semantic Search. Let's build a FAQ system! ! Sentence transformers are powerful models that can measure semantic text similarity. While the transformer encoder usually outputs an embedding for each token, sentence transformers output an embedding for the whole input text, allowing us to determine if two texts have similar meanings based on their similarity score. Let’s look at a simple example using the `sentence_transformers` library.**"
      ],
      "metadata": {
        "id": "qpXQcGda-8RN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the example provided in the book. We first load the `all-MiniLM-L6-v2` model from the Hub. We then use it to compute the embedding of two sentences using the `encode` method. Each is a tensor (vector) of 384 values. We finally compute the cosine similarity to determine how close both tensors are."
      ],
      "metadata": {
        "id": "pkIsfaHU-8RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "sentences = [\"I'm happy\", \"I'm full of happiness\"]\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Compute embedding for both lists\n",
        "embedding_1 = model.encode(sentences[0], convert_to_tensor=True)\n",
        "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
        "\n",
        "util.pytorch_cos_sim(embedding_1, embedding_2)"
      ],
      "metadata": {
        "id": "L4DtdkKn-8RN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll write a dictionary of 5 questions and answers based on Medicare FAQ website."
      ],
      "metadata": {
        "id": "1xXXFEh6-8RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from https://faq.ssa.gov/en-US/topic/?id=CAT-01092\n",
        "\n",
        "faq = {\n",
        "    \"How do I get a replacement Medicare card?\": \"If your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov.\",\n",
        "    \"How do I sign up for Medicare?\": \"If you already get Social Security benefits, you do not need to sign up for Medicare. We will automatically enroll you in Original Medicare (Part A and Part B) when you become eligible. We will mail you the information a few months before you become eligible.\",\n",
        "    \"What are Medicare late enrollment penalties?\": \"In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\",\n",
        "    \"Will my Medicare premiums be higher because of my higher income?\": \"Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\",\n",
        "    \"What is Medicare and who can get it?\": \"Medicare is a health insurance program for people age 65 or older. Some younger people are eligible for Medicare including people with disabilities, permanent kidney failure and amyotrophic lateral sclerosis (Lou Gehrig’s disease or ALS). Medicare helps with the cost of health care, but it does not cover all medical expenses or the cost of most long-term care.\",\n",
        "}"
      ],
      "metadata": {
        "id": "z-QiA4gm-8RN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the `encode` method to compute the embedding of the 5 questions."
      ],
      "metadata": {
        "id": "CaNCW0oq-8RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings = model.encode(list(faq.values()), convert_to_tensor=True)\n",
        "print(corpus_embeddings.shape)"
      ],
      "metadata": {
        "id": "ZVGqLI8m-8RN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, in a production setup, a user would input a question. We can compute its embedding as well."
      ],
      "metadata": {
        "id": "o4HAnMFl-8RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = \"Do I need to pay more after a raise?\"\n",
        "query_embedding = model.encode(user_question, convert_to_tensor=True)\n",
        "query_embedding.shape"
      ],
      "metadata": {
        "id": "0nIi_HAV-8RO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, using cosine similarity, we can retrieve the most similar questions from the database - that is, we retrieve the most similar questions based on the highest similarity.\n",
        "\n",
        "Using `argsort`, we get the top 3 questions and print them."
      ],
      "metadata": {
        "id": "szvTJFiW-8RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "similarities = -util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "top_3 = similarities.cpu().argsort()[:3]\n",
        "for i, top_n in enumerate(top_3):\n",
        "    print(\n",
        "        f\"Top {i+1} question (p={-similarities[top_n]}): {list(faq.keys())[top_n]}\"\n",
        "    )\n",
        "    print(f\"Answer: {list(faq.values())[top_n]}\")"
      ],
      "metadata": {
        "id": "Z-EpYN3h-8RO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sentence_transformers` also offers a convenient utility called `semantic_search` for exactly this use case."
      ],
      "metadata": {
        "id": "Ua8B277W-8RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = util.semantic_search(\n",
        "    query_embedding, corpus_embeddings, top_k=3\n",
        ")[0]\n",
        "for i, result in enumerate(similarities):\n",
        "    corpus_id = result[\"corpus_id\"]\n",
        "    score = result[\"score\"]\n",
        "    print(f\"Top {i+1} question (p={score}): {list(faq.keys())[corpus_id]}\")\n",
        "    print(f\"Answer: {list(faq.values())[corpus_id]}\")"
      ],
      "metadata": {
        "id": "YgUYMFi0-8RO"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}